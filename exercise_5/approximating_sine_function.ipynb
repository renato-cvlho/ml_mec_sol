{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7 - Approximating the Sine function\n",
    "## Task\n",
    "Approximate the sine function with a fully connected neural network using PyTorch.\n",
    "\n",
    "Subtasks:\n",
    "- Change the neural network architecture to a single hidden layer with two neurons.\n",
    "  - What do you observe?\n",
    "- Increase the number of neurons per layer and the number of layers. Try, e.g., [2] and [50,50]. What do you observe?\n",
    "  - Name ways to overcome this problem.\n",
    "- Take a look at the cost function history. At what epoch should the algorithm stop to prevent overfitting?\n",
    "- Set the learning rate to α = 0.1. What do you observe?\n",
    "- Reset the learning rate to α = 0.001 and set λ > 0 where the model fits the sine curve without overfitting.\n",
    "- Increase λ until underfitting occurs and plot the result.\n",
    "- Change the model to use ReLU activation function and plot the result.\n",
    "- Why does the neural network not learn the sine function properly at the boundaries (and beyond the boundaries)?\n",
    "\n",
    "## Learning Goals\n",
    "- Get an understanding of the code and introduction to model training.\n",
    "- Influence of hyperparameters on model fit - which hyperparameters are the most important?\n",
    "- Change the non-linear activation function to ReLU instead of Sigmoid.\n",
    "- Why does the model not learn the sine curve properly at the boundaries? Is there any remedy to this problem? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T16:39:51.477291851Z",
     "start_time": "2023-12-22T16:39:51.446244151Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**data generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T16:39:51.479292344Z",
     "start_time": "2023-12-22T16:39:51.477482995Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "f = lambda x: torch.sin(2 * torch.pi * x)\n",
    "\n",
    "numberOfSamples = 40  # number of samples\n",
    "noise = 0.1  # random noise added to the training and validation data\n",
    "\n",
    "xTrain = torch.rand((numberOfSamples, 1)) * 2 - 1\n",
    "yTrain = f(xTrain) + noise * (torch.rand(xTrain.shape) * 2 - 1)\n",
    "\n",
    "xTest = torch.rand((numberOfSamples, 1)) * 2 - 1\n",
    "yTest = f(xTest) + noise * (torch.rand(xTest.shape) * 2 - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T16:39:51.490254393Z",
     "start_time": "2023-12-22T16:39:51.480361243Z"
    }
   },
   "outputs": [],
   "source": [
    "inputDimension = 1\n",
    "hiddenDimensions = [20, 20]  # e.g. [20, 20] for 2 hidden layers with 20 neurons each\n",
    "outputDimension = 1\n",
    "\n",
    "nonlinearity = torch.nn.Sigmoid()  # torch.nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T16:39:51.490652254Z",
     "start_time": "2023-12-22T16:39:51.488682139Z"
    }
   },
   "outputs": [],
   "source": [
    "modules = []\n",
    "modules.append(torch.nn.Linear(inputDimension, hiddenDimensions[0]))\n",
    "modules.append(nonlinearity)\n",
    "for i in range(len(hiddenDimensions) - 1):\n",
    "    modules.append(torch.nn.Linear(hiddenDimensions[i], hiddenDimensions[i + 1]))\n",
    "    modules.append(nonlinearity)\n",
    "\n",
    "modules.append(torch.nn.Linear(hiddenDimensions[-1], outputDimension))\n",
    "\n",
    "model = torch.nn.Sequential(*modules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hyperparameters & optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T16:39:51.499151926Z",
     "start_time": "2023-12-22T16:39:51.491701191Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "lr = 1e-3\n",
    "regularization = 1e-4\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr, weight_decay=regularization\n",
    ")  # weight_decay is L2 regularization in Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cost function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T16:39:51.539650559Z",
     "start_time": "2023-12-22T16:39:51.494605231Z"
    }
   },
   "outputs": [],
   "source": [
    "def costFunction(yPred, y):\n",
    "    cost = torch.mean((yPred - y) ** 2)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**training loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T16:39:55.549542233Z",
     "start_time": "2023-12-22T16:39:51.539544327Z"
    }
   },
   "outputs": [],
   "source": [
    "costHistoryTrain = np.zeros(epochs)\n",
    "costHistoryTest = np.zeros(epochs)\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    yPred = model(xTrain)\n",
    "    cost = costFunction(yPred, yTrain)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        yPredTest = model(xTest)\n",
    "        costTest = costFunction(yPredTest, yTest)\n",
    "\n",
    "    costHistoryTrain[epoch] = cost.detach()\n",
    "    costHistoryTest[epoch] = costTest\n",
    "\n",
    "    cost.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        string = \"Epoch: {}/{}\\t\\tTraining cost = {:.2e}\\t\\tValidation cost = {:.2e}\"\n",
    "        print(string.format(epoch, epochs, cost.detach(), costTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**visualize the prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T16:39:55.673161479Z",
     "start_time": "2023-12-22T16:39:55.549254969Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.linspace(-1.2, 1.2, 100).unsqueeze(1)\n",
    "yPred = model(x).detach()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.grid()\n",
    "ax.plot(x, yPred, \"k\", label=\"prediction\")\n",
    "ax.scatter(xTrain, yTrain, color=\"k\", label=\"training data\")\n",
    "ax.scatter(xTest, yTest, color=\"r\", label=\"validation data\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**visualize the training history**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T16:39:55.911946772Z",
     "start_time": "2023-12-22T16:39:55.682559823Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.grid()\n",
    "ax.plot(costHistoryTrain, \"k\", label=\"training cost\")\n",
    "ax.plot(costHistoryTest, \"r\", label=\"validation cost\")\n",
    "ax.legend()\n",
    "ax.set_yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**compute derivative visualization for reference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(-1.2, 1.2, 100, requires_grad=True).unsqueeze(1)\n",
    "yPred = model(x)\n",
    "gradients = torch.autograd.grad(yPred, x, grad_outputs=torch.ones_like(yPred))[0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.grid()\n",
    "ax.plot(x.detach().numpy(), yPred.detach().numpy(), \"k\", label=\"prediction\")\n",
    "ax.plot(x.detach().numpy(), gradients, 'g', label='gradient')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python . (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
